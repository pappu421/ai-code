=====================================
KNN 
import numpy as np
from sklearn import datasets
from sklearn import neighbors
import pylab as pl
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
iris = datasets.load_iris()                  
print(iris.keys())
n_samples, n_features = iris.data.shape
print((n_samples, n_features))
print(iris.data[0])
print(iris.target.shape)
print(iris.target)
print(iris.target_names)
x_index = 0
y_index = 1
# this formatter will label the colorbar with the correct target 
formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])
plt.scatter(iris.data[:, x_index], iris.data[:, y_index],
            c=iris.target, cmap=plt.cm.get_cmap('RdYlBu', 3))
plt.colorbar(ticks=[0, 1, 2], format=formatter)
plt.clim(-0.5, 2.5)
plt.xlabel(iris.feature_names[x_index])
plt.ylabel(iris.feature_names[y_index]);
X, y = iris.data, iris.target
clf = neighbors.KNeighborsClassifier(n_neighbors=5)
clf.fit(X, y)
result = clf.predict([[3, 5, 4, 2],])
print(iris.target_names[result])
 

# Create color maps for 3-class classification problem, as with iris
cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])
cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])
def plot_iris_knn():
    iris = datasets.load_iris()
    X = iris.data[:, :2]  # we only take the first two features.
    y = iris.target
    knn = neighbors.KNeighborsClassifier(n_neighbors=3)
    knn.fit(X, y)
    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1
    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                         np.linspace(y_min, y_max, 100))
    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])
    # Put the result into a color plot
    Z = Z.reshape(xx.shape)
    pl.figure()
    pl.pcolormesh(xx, yy, Z, cmap=cmap_light)
    # Plot also the training point
    pl.scatter(X[:, 0], X[:, 1], c=y,cmap=cmap_bold)
    pl.xlabel('sepal length (cm)')
    pl.ylabel('sepal width (cm)')
    pl.axis('tight')
plot_iris_knn()


============================================== 
KNN with dataset

from google.colab import files
upload = files.upload()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Load the dataset from CSV file
def load_data(filename):
    data = pd.read_csv(filename)
    X = data[['Age', 'EstimatedSalary']]  # Features: Age and EstimatedSalary
    y = data['Purchased']                 # Target variable: Purchased
    return X, y

# Split the dataset into training and testing sets
def split_data(X, y, test_size=0.2, random_state=None):
    return train_test_split(X, y, test_size=test_size, random_state=random_state)

# Train the KNN model
def train_knn(X_train, y_train, n_neighbors=5):
    knn = KNeighborsClassifier(n_neighbors=n_neighbors)
    knn.fit(X_train, y_train)
    return knn

# Test the trained model
def test_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    return accuracy, y_pred

if __name__ == "__main__":
    # Change this to your CSV file path
    filename = "User_Data.csv"

    # Load data
    X, y = load_data(filename)

    # Split data into train and test sets
    X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.2, random_state=42)

    # Train KNN model
    model = train_knn(X_train, y_train)

    # Test the model
    accuracy, predictions = test_model(model, X_test, y_test)
    print("Accuracy:", accuracy)
    print("Predictions:\n", predictions)



